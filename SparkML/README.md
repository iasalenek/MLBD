### Spark ML (40 баллов)

Файл `basic_pipeline.py` содержит базовый препроцессинг, состоящий из следующих шагов:
- разделение датасета на обучающий и тестовый
- выбор фичей, имеющих более одного уникального значений на обучающем датасете
- индексирование всех строковых колонок и one-hot-encoding для фичей

После трансформаций из препроцессинга обучающий и тестовый датасеты были закешированы для обучения нескольких моделей.

В файле `basic_pipeline.py` все модели были построены с дефолтными параметрами, так как они и так давали хорошие результаты:

| Model             | Test Error|
|-------------------|-----------|
| Linear Regression | 0         |
| Naive Bayes       | 0.0643234 |
| SVM               | 0         |
| Decision Trees    | 0.00105448|
| Random Forest     | 0.0239016 |

Так как улучшать наилучшую модель подбором гиперпараметров не имело смысла (ошибка на тестовой выборке равна 0), я попробовал улучшить худшую из моделей -- Naive Bayes. В PySpark он имеет мало настраиваемых параметров (по сути только smoothing и modelType). В файле `cv_pipeline.py` я выбираю лучшие smoothing параметр на сетке `[0, 0.001, 0.01, 0.1, 1]` при помощи 3-x фолдовой кросс-валидации. В резултате наилучшим оказался параметр smoothing = 0 (вместо дефолтного 1), при этом ошибку на тестовой выборке удалось уменьшить в 10 раз, по сравнению с дефолтным Naive Bayes:

| Model             | Test Error|
|-------------------|-----------|
| Naive Bayes_cv    | 0.005341  |